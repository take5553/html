# Image Classification（Deep Learning部）

コードは大きく分けて

* Interactive Form（iPython widget）
* Deep Leaning（PyTorch）

に分かれる。

ここでは後半のDeep Leaning部に注目する。

Deep Leaningでは

* 学習
* 予測

の2つに分かれる。

## 学習部分

学習は`train_eval_widget`作成時に出てきた関数`train_eval`で行われるが、そのためにはインポートするライブラリ以外に以下のものを準備する必要がある。

* `dataset`
* `model`

### `dataset`について

~~~python
import torchvision.transforms as transforms
from dataset import ImageClassificationDataset

TASK = 'thumbs'
# TASK = 'emotions'
# TASK = 'fingers'
# TASK = 'diy'

CATEGORIES = ['thumbs_up', 'thumbs_down']
# CATEGORIES = ['none', 'happy', 'sad', 'angry']
# CATEGORIES = ['1', '2', '3', '4', '5']
# CATEGORIES = [ 'diy_1', 'diy_2', 'diy_3']

DATASETS = ['A', 'B']
# DATASETS = ['A', 'B', 'C']

TRANSFORMS = transforms.Compose([
    transforms.ColorJitter(0.2, 0.2, 0.2, 0.2),
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

datasets = {}
for name in DATASETS:
    datasets[name] = ImageClassificationDataset('../data/classification/' + TASK + '_' + name, CATEGORIES, TRANSFORMS)
~~~

大まかに見ると、現状では

* `datasets['A']`
* `datasets['B']`

があり、それらは`ImageClassificationDataset`というクラスのインスタンスが格納される。

#### `ImageClassificationDataset`クラス（`torch.utils.data.Dataset`を継承）

（`classification_interactive.ipynb`と同じディレクトリにある`dataset.py`にそのソースがある）

メンバ変数は以下の通り。

* `categories`
* `directory`
* `transform`
* `annotations`（リストの中に以下のキーを持つ辞書が格納される：保存した画像数に応じて可変）
  * `'image_path'`
  * `'category_index'`
  * `'category'`

役割としては、

* カメラ画像の保存
* 保存した画像の情報（保存場所とその画像が属するカテゴリ名）の管理
* PyTorchに、画像（に前処理を加えたもの）とラベルをセットにして引き渡す

というものがある。

そもそも`torch.utils.data.Dataset`を継承していることから、PyTorchに引き渡す用のデータセットという宿命を背負っていることになる。この引き渡される用のデータセットは`__getitem__`と`__len__`をオーバーライドしている必要がある。（これをMap-style datasetsという。もう一つ、Iterable-style datasetsというものがあって、こちらは`IterableDataset`を継承している必要がある。詳しくは[公式マニュアル](https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset)へ。）

一つの`ImageClassificationDataset`は、そのままであれば`thums_up`と`thums_down`という2つのカテゴリを管理する。

#### `TRANSFORMS`について

学習時にPyTorchに画像データを渡す際の前処理。

~~~python
TRANSFORMS = transforms.Compose([
    transforms.ColorJitter(0.2, 0.2, 0.2, 0.2),
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])
~~~

以下の4つを`Compose`で一つにまとめている、という感じ。登録順に実行される。

* `ColorJitter`・・・明るさ、コントラスト、彩度、色相をランダムに変動させる。引数はこの順で、数値は変動幅（この例の場合、±2割）を表す

* `Resize`・・・画像のリサイズ

* `ToTensor`・・・画像をPyTorchのTensor型（PyTorchで使われる専用の配列）に変換

* `Normalize`・・・正規化（平均の配列と標準偏差の配列を渡す）

  ここではtorchvisionの学習済みモデルを使用するので、[公式ドキュメント]()でその平均と標準偏差が指定されている。それぞれ3つあるのは、入力画像がRGBの3つのチャンネルを持つから。（結局のところ入力画像というのはOpenCVの`VideoCapture.read()`から入力されたデータ）

  

## 参考

[pyTorchのtransforms,Datasets,Dataloaderの説明と自作Datasetの作成と使用 - Qiita](https://qiita.com/mathlive/items/2a512831878b8018db02)
[torch.utils.data — PyTorch 1.9.0 documentation](https://pytorch.org/docs/stable/data.html)
[Pytorch - DataLoader の使い方について解説 - pystyle](https://pystyle.info/pytorch-dataloader/)

[torchvision.transforms — Torchvision 0.10.0 documentation](https://pytorch.org/vision/stable/transforms.html#)
[torchvision.models — Torchvision 0.10.0 documentation](https://pytorch.org/vision/stable/models.html)

[pyTorchのTensor型とは - Qiita](https://qiita.com/mathlive/items/241bfb42d852bb801b96)
[PyTorchでTensorとモデルのGPU / CPUを指定・切り替え | note.nkmk.me](https://note.nkmk.me/python-pytorch-device-to-cuda-cpu/)
[PytorchでのGPUの使用方法 | でい tech blog](https://deideeplearning.com/2020/04/03/pytorch-gpu/)

