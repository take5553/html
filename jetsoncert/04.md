# Image Classification（Deep Learning部）

コードは大きく分けて

* Interactive Form（iPython widget）
* Deep Leaning（PyTorch）

に分かれる。

ここでは後半のDeep Leaning部に注目する。

Deep Leaningでは

* 学習
* 予測

の2つに分かれる。

## 学習部分

学習は`train_eval_widget`作成時に出てきた関数`train_eval`で行われるが、そのためにはインポートするライブラリ以外に以下のものを準備する必要がある。

* `dataset`
* `model`

### `dataset`について

~~~python
import torchvision.transforms as transforms
from dataset import ImageClassificationDataset

TASK = 'thumbs'
# TASK = 'emotions'
# TASK = 'fingers'
# TASK = 'diy'

CATEGORIES = ['thumbs_up', 'thumbs_down']
# CATEGORIES = ['none', 'happy', 'sad', 'angry']
# CATEGORIES = ['1', '2', '3', '4', '5']
# CATEGORIES = [ 'diy_1', 'diy_2', 'diy_3']

DATASETS = ['A', 'B']
# DATASETS = ['A', 'B', 'C']

TRANSFORMS = transforms.Compose([
    transforms.ColorJitter(0.2, 0.2, 0.2, 0.2),
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

datasets = {}
for name in DATASETS:
    datasets[name] = ImageClassificationDataset('../data/classification/' + TASK + '_' + name, CATEGORIES, TRANSFORMS)
~~~

大まかに見ると、現状では

* `datasets['A']`
* `datasets['B']`

があり、それらは`ImageClassificationDataset`というクラスのインスタンスが格納される。

#### `ImageClassificationDataset`クラス（`torch.utils.data.Dataset`を継承）

（`classification_interactive.ipynb`と同じディレクトリにある`dataset.py`にそのソースがある）

メンバ変数は以下の通り。

* `categories`
* `directory`
* `transform`
* `annotations`（リストの中に以下のキーを持つ辞書が格納される：保存した画像数に応じて可変）
  * `'image_path'`
  * `'category_index'`
  * `'category'`

役割としては、

* カメラ画像の保存
* 保存した画像の情報（保存場所とその画像が属するカテゴリ名）の管理
* PyTorchに、画像（に前処理を加えたもの）とラベルをセットにして引き渡す

というものがある。

そもそも`torch.utils.data.Dataset`を継承していることから、PyTorchに引き渡す用のデータセットという宿命を背負っていることになる。この引き渡される用のデータセットは`__getitem__`と`__len__`をオーバーライドしている必要がある。（これをMap-style datasetsという。もう一つ、Iterable-style datasetsというものがあって、こちらは`IterableDataset`を継承している必要がある。詳しくは[公式マニュアル](https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset)へ。）

一つの`ImageClassificationDataset`は、そのままであれば`thums_up`と`thums_down`という2つのカテゴリを管理する。

#### `TRANSFORMS`について

学習時にPyTorchに画像データを渡す際の前処理。

~~~python
TRANSFORMS = transforms.Compose([
    transforms.ColorJitter(0.2, 0.2, 0.2, 0.2),
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])
~~~

以下の4つを`Compose`で一つにまとめている、という感じ。登録順に実行される。

* `ColorJitter`・・・明るさ、コントラスト、彩度、色相をランダムに変動させる。引数はこの順で、数値は変動幅（この例の場合、±2割）を表す

* `Resize`・・・画像のリサイズ

* `ToTensor`・・・画像をPyTorchのTensor型（PyTorchで使われる専用の配列）に変換

* `Normalize`・・・正規化（平均の配列と標準偏差の配列を渡す）

  ここではtorchvisionの学習済みモデルを使用するので、[公式ドキュメント]()でその平均と標準偏差が指定されている。それぞれ3つあるのは、入力画像がRGBの3つのチャンネルを持つから。（結局のところ入力画像というのはOpenCVの`VideoCapture.read()`から入力されたデータ）

### `model`について（生成）

~~~python
import torch
import torchvision


device = torch.device('cuda')

# ALEXNET
# model = torchvision.models.alexnet(pretrained=True)
# model.classifier[-1] = torch.nn.Linear(4096, len(dataset.categories))

# SQUEEZENET 
# model = torchvision.models.squeezenet1_1(pretrained=True)
# model.classifier[1] = torch.nn.Conv2d(512, len(dataset.categories), kernel_size=1)
# model.num_classes = len(dataset.categories)

# RESNET 18
model = torchvision.models.resnet18(pretrained=True)
model.fc = torch.nn.Linear(512, len(dataset.categories))

# RESNET 34
# model = torchvision.models.resnet34(pretrained=True)
# model.fc = torch.nn.Linear(512, len(dataset.categories))
    
model = model.to(device)
~~~

#### ResNet-18

まずは実際に実行されている行を見ていく。

~~~python
import torch
import torchvision

device = torch.device('cuda')

(略)

model = torchvision.models.resnet18(pretrained=True)
model.fc = torch.nn.Linear(512, len(dataset.categories))

(略)

model = model.to(device)
~~~

* `torchvision.models.resnet18`・・・ResNet-18というモデルを生成する。

  * 本コースの解説によれば、層を飛び越してショートカットするルートを持つモデルとのこと。[参考](https://arxiv.org/pdf/1512.03385.pdf)

  * 引数の`pretrained=True`は事前学習済みのモデルを使用するという意味で、すでに1000個の分類ができるようになっているとのこと。ただし今回は1000個も使わないので、全結合層（`model.fc`）を「Input:`512`, Output:`2`」となるような線形変換関数に上書きしてしまう。こうすることで結果の出口が2個しかなくなり、結果的に2つの分類になるというわけ。この`512`という数字の由来はResNet-18の構造から、`2`という数字は`thums_up`と`thums_down`の2つという意味。

  * `torch.nn.Linear`・・・線形変換の指定。

    実際は入力`x`に対して、出力`y`を以下のように計算する。
    $$
    y=xA^{-1}+b
    $$
    おそらく

    * `x`：`(バッチ数, 512)`の行列
    * `A^{-1}`：`(512, 3)`の行列
    * `b`：バイアス、`(バッチ数, 3)`の行列
    
    使用するときはこんな数式考えなくてよくて、単に「1レコード512個のデータを1レコード3個のデータに変換するんだな」ぐらいで良い。Nレコードを同時に処理＋学習可能という理由から行列が採用されたんだと思う。
  

#### 他のモデル

コメントに書かれているのはAlexNet、SqueezeNet、ResNet-34だけど[他にも色々あるらしい](https://pytorch.org/vision/stable/models.html)。どれも共通して、最終層の出力を`3`に修正する必要があるらしい。

#### 他の部分

~~~python
device = torch.device('cuda')

model = model.to(device)
~~~

後半の行が重要で、前半は`device`という変数を定義しているだけ。

で、この`to()`というメソッドは「`model`をGPUのメモリ上に配置している」ということらしい。

`torch.device`の引数は

* `'cpu'`
* `'cuda'`（または`'cuda:0'`）

で、作成したモデルをどこに置くかを指定する。`cuda`を指定すればGPU上に置く、とのことらしい。これができるためには[CUDA Toolkit](https://developer.nvidia.com/cuda-toolkit)がインストールされている必要がある。そしてCUDAはバージョン指定があるらしい。[PyTorch公式](https://pytorch.org/)によると、`pip3`とかですっと入るPyTorchに合うCUDAはv10.2らしい。CUDAの最新はv11.4なので注意(2021/07現在)

### `model`について（セーブ＆ロード）

~~~python
def load_model(c):
    model.load_state_dict(torch.load(model_path_widget.value))
model_load_button.on_click(load_model)
    
def save_model(c):
    torch.save(model.state_dict(), model_path_widget.value)
model_save_button.on_click(save_model)
~~~

どちらも`torch.load`、`torch.save`が本質らしい。

* `torch.save(セーブ対象オブジェクト、場所)`
  * `model.state_dict()`で、`model`が持つ「状態（state）」の全てを持つ辞書を出力する。
* `torch.load(場所)`
  * オブジェクトを読みこむ→`model.state_dict()`で出力されたものが読み込まれる
  * `model.load_sate_dict`で`state_dict()`を読み込む。

### 学習（関数`train_eval`の中身）について

#### 概要

1. `DataLoader`に`dataset`を渡してDataLoaderインスタンスを作成
2. `train_loader`が少しずつデータを吐き出し、`model`に渡して学習する
3. 進行具合、誤差、正確さを計算しWidgetに反映
4. 2と3を繰り返す

#### コード

~~~python
BATCH_SIZE = 8

optimizer = torch.optim.Adam(model.parameters())
# optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=0.9)

(略)

def train_eval(is_training):
    global BATCH_SIZE, LEARNING_RATE, MOMENTUM, model, dataset, optimizer, eval_button, train_button, accuracy_widget, loss_widget, progress_widget, state_widget
    
    try:
        train_loader = torch.utils.data.DataLoader(
            dataset,
            batch_size=BATCH_SIZE,
            shuffle=True
        )

        state_widget.value = 'stop'
        train_button.disabled = True
        eval_button.disabled = True
        time.sleep(1)

        if is_training:
            model = model.train()
        else:
            model = model.eval()
        while epochs_widget.value > 0:
            i = 0
            sum_loss = 0.0
            error_count = 0.0
            for images, labels in iter(train_loader):
                # send data to device
                images = images.to(device)
                labels = labels.to(device)

                if is_training:
                    # zero gradients of parameters
                    optimizer.zero_grad()

                # execute model to get outputs
                outputs = model(images)

                # compute loss
                loss = F.cross_entropy(outputs, labels)

                if is_training:
                    # run backpropogation to accumulate gradients
                    loss.backward()

                    # step optimizer to adjust parameters
                    optimizer.step()

                # increment progress
                error_count += len(torch.nonzero(outputs.argmax(1) - labels).flatten())
                count = len(labels.flatten())
                i += count
                sum_loss += float(loss)
                progress_widget.value = i / len(dataset)
                loss_widget.value = sum_loss / i
                accuracy_widget.value = 1.0 - error_count / i
                
            if is_training:
                epochs_widget.value = epochs_widget.value - 1
            else:
                break
    except e:
        pass
    model = model.eval()

    train_button.disabled = False
    eval_button.disabled = False
    state_widget.value = 'live'
    
train_button.on_click(lambda c: train_eval(is_training=True))
eval_button.on_click(lambda c: train_eval(is_training=False))
~~~

#### 詳細

バッチサイズは一度に何枚の画像を学習させるか。`optimizer`は学習方法の指定。学習と言っても色々ある。

~~~python
BATCH_SIZE = 8

optimizer = torch.optim.Adam(model.parameters())
# optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=0.9)
~~~

`DataLoader`クラスの生成。`dataset`は前述の通り、合うように作ってあげる。

~~~python
        train_loader = torch.utils.data.DataLoader(
            dataset,
            batch_size=BATCH_SIZE,
            shuffle=True
        )
~~~

`model.train()`も`model.eval()`も`module`インスタンスを返す。違いは内部変数のスイッチ。

~~~python
        if is_training:
            model = model.train()
        else:
            model = model.eval()
~~~

エポックは本コースの説明動画にもあったけど、何回学習するか。`for`ループは画像データが無くなるまで続く。学習モードなら学習回数を反映してループ、評価モードなら1回で終わり。

~~~python
        while epochs_widget.value > 0:
            i = 0
            sum_loss = 0.0
            error_count = 0.0
            for images, labels in iter(train_loader):
                (後述)
                
            if is_training:
                epochs_widget.value = epochs_widget.value - 1
            else:
                break
~~~

##### `for`ループの中身

~~~python
            for images, labels in iter(train_loader):
                # send data to device
                images = images.to(device)
                labels = labels.to(device)

                if is_training:
                    # zero gradients of parameters
                    optimizer.zero_grad()

                # execute model to get outputs
                outputs = model(images)

                # compute loss
                loss = F.cross_entropy(outputs, labels)

                if is_training:
                    # run backpropogation to accumulate gradients
                    loss.backward()

                    # step optimizer to adjust parameters
                    optimizer.step()

                # increment progress
                (後述)
~~~

`iter(train_loader)`がうまく画像データとそのラベル（ただし文字列ではなく数値）を出力してくれている。実際は`ImageClassificationDataset`クラス（`dataset`はこのクラスのインスタンス）の`__getitem__`の出力による。おそらく、`train_loader`がバッチサイズに合うように上手くまとめて`images`、`labels`をどちらもTensor型にしていると思われる。だからどちらも`to()`メソッドが使えている。

`optimizer.zero_grad()`は各Tensor型変数が持つ勾配をリセットしている。

~~~python
                # send data to device
                images = images.to(device)
                labels = labels.to(device)

                if is_training:
                    # zero gradients of parameters
                    optimizer.zero_grad()
~~~

以下は予測と評価。`model`はクラスのインスタンスなのに、関数っぽい使い方をしているのはPythonの機能。メンバメソッドとして`__call__`を定義するとこういう使い方ができる。文脈からして、予測（Forward）をしているのは明らか。

`loss`の計算は交差エントロピー。ここで[「ありゃ、交差エントロピーはソフトマックスと組み合わせて使うんじゃなかったっけ？」](../deepleaning/activate_function.html)と思ったけど、実は内部的にソフトマックスが適用されているらしい。正確にはLog_SoftmaxとNull_Lossの組み合わせ。なので逆にこの`cross_entropy`にはソフトマックスを適用していないものを入力する。

参考：[torch.nn.functional.cross_entropy — PyTorch 1.9.0 documentation](https://pytorch.org/docs/stable/generated/torch.nn.functional.cross_entropy.html#torch.nn.functional.cross_entropy)
参考：[LogSoftmax — PyTorch 1.9.0 documentation](https://pytorch.org/docs/stable/generated/torch.nn.LogSoftmax.html)
参考：[pytorch の NLLLoss の挙動 - メモ](https://tatsukawa.hatenablog.com/entry/2020/04/06/054700)

~~~python
                # execute model to get outputs
                outputs = model(images)

                # compute loss
                loss = F.cross_entropy(outputs, labels)
~~~

以下は学習。

`loss`はTensor型で、勾配情報を持つことができる別のTensor型変数が計算途中にあったので、`loss`が`backward()`を持たされた。その`backward()`を実行すると計算途中に出てきた各Tensor型変数に対する勾配情報を自動で計算（微分）してくれる。その勾配情報は`loss`が持つのではなく、各Tensor型変数が持っている。

`optimizer`の内部には、生成時に渡された`model.parameters()`がある。そのパラメーターたちは上記の各Tensor型変数（勾配情報あり）なのだろう。で、`optimizer.step()`でそれらのパラメーターたちを、それぞれの勾配を使って更新していく、という感じか。ほぼ予測だけどまあまあ調べた。

~~~python
                if is_training:
                    # run backpropogation to accumulate gradients
                    loss.backward()

                    # step optimizer to adjust parameters
                    optimizer.step()
~~~



## 参考

[pyTorchのtransforms,Datasets,Dataloaderの説明と自作Datasetの作成と使用 - Qiita](https://qiita.com/mathlive/items/2a512831878b8018db02)
[torch.utils.data — PyTorch 1.9.0 documentation](https://pytorch.org/docs/stable/data.html)
[Pytorch - DataLoader の使い方について解説 - pystyle](https://pystyle.info/pytorch-dataloader/)

[torchvision.transforms — Torchvision 0.10.0 documentation](https://pytorch.org/vision/stable/transforms.html#)
[torchvision.models — Torchvision 0.10.0 documentation](https://pytorch.org/vision/stable/models.html)

[pyTorchのTensor型とは - Qiita](https://qiita.com/mathlive/items/241bfb42d852bb801b96)
[PyTorchでTensorとモデルのGPU / CPUを指定・切り替え | note.nkmk.me](https://note.nkmk.me/python-pytorch-device-to-cuda-cpu/)
[PytorchでのGPUの使用方法 | でい tech blog](https://deideeplearning.com/2020/04/03/pytorch-gpu/)

[torch.nn — PyTorch 1.9.0 documentation](https://pytorch.org/docs/1.9.0/nn.html#linear-layers)
[転移学習モデルを利用して画像分類 with Pytorch｜なる｜note](https://note.com/nago_ai_ru/n/n62aaa47d073e)
[Training a Classifier — PyTorch Tutorials 1.9.0+cu102 documentation](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#sphx-glr-beginner-blitz-cifar10-tutorial-py)
[transfer_learning_resnet.ipynb - Colaboratory](https://colab.research.google.com/drive/1l7wRfwS2TYSti5XXyjM8PFfH_PsN8Feo#scrollTo=ruVIiVKKlKEQ)

[PyTorch による画像分類と転移学習](https://www.koi.mashykom.com/pytorch.html)

[Deep Learning](https://www.koi.mashykom.com/deep_learning.html)

[Tensor Attributes — PyTorch 1.9.0 documentation](https://pytorch.org/docs/stable/tensor_attributes.html?highlight=torch%20device#torch.torch.device)

[Pytorchの基礎 forwardとbackwardを理解する](https://zenn.dev/hirayuki/articles/bbc0eec8cd816c183408)
[torch.optim — PyTorch 1.9.0 documentation](https://pytorch.org/docs/stable/optim.html)
[pyTorchのTensor型とは - Qiita](https://qiita.com/mathlive/items/241bfb42d852bb801b96)
